{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 005 - Time series modelling - Detecting potential changes in road network\n",
    "#### This script integrates all the previous results and recomputes both steps 001 and 002 and performs a time series analysis to compare higher spatiotemporal resolution modelled traffic conditions for new input queried data and compares the result to the expected traffic conditions (\"Normal conditions\") to detect potential changes in the road network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(574627, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>speed</th>\n",
       "      <th>session_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-06 06:00:03</td>\n",
       "      <td>323433.595226</td>\n",
       "      <td>5.817266e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6e79f1066cd34a42a8c1a8c37b0b0b78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-05-06 06:10:48</td>\n",
       "      <td>323160.745335</td>\n",
       "      <td>5.808077e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>e26618cb8d954ec4b84061bc1cfed52a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-06 06:15:09</td>\n",
       "      <td>323160.745335</td>\n",
       "      <td>5.808077e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>e26618cb8d954ec4b84061bc1cfed52a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-06 06:17:09</td>\n",
       "      <td>323160.745335</td>\n",
       "      <td>5.808077e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>e26618cb8d954ec4b84061bc1cfed52a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-06 06:19:34</td>\n",
       "      <td>317410.180464</td>\n",
       "      <td>5.830074e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ebef98c0d1c4407b8a17e1c6382d671b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           local_time              x             y  speed  \\\n",
       "0 2016-05-06 06:00:03  323433.595226  5.817266e+06    2.0   \n",
       "1 2016-05-06 06:10:48  323160.745335  5.808077e+06    0.0   \n",
       "2 2016-05-06 06:15:09  323160.745335  5.808077e+06    0.0   \n",
       "3 2016-05-06 06:17:09  323160.745335  5.808077e+06    0.0   \n",
       "4 2016-05-06 06:19:34  317410.180464  5.830074e+06    0.0   \n",
       "\n",
       "                         session_id  \n",
       "0  6e79f1066cd34a42a8c1a8c37b0b0b78  \n",
       "1  e26618cb8d954ec4b84061bc1cfed52a  \n",
       "2  e26618cb8d954ec4b84061bc1cfed52a  \n",
       "3  e26618cb8d954ec4b84061bc1cfed52a  \n",
       "4  ebef98c0d1c4407b8a17e1c6382d671b  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "#spatial libraries\n",
    "import fiona\n",
    "from shapely.geometry import shape, Point, mapping\n",
    "from shapely.ops import linemerge\n",
    "import pandas as pd\n",
    "import mapmatcher as mm #Map matching algorithm \n",
    "\n",
    "startTime = datetime.now()  # Record the start time of the task\n",
    "\n",
    "# Read data from DB \n",
    "engine = create_engine('postgresql://postgres:gumbinis54@localhost:5432/ie research')\n",
    "df = pd.read_sql_query( \"\"\"SELECT \n",
    "                                 local_time, \n",
    "                                 ST_X(points.geom) as x, \n",
    "                                 ST_Y(points.geom) as y ,\n",
    "                                 speed, \n",
    "                                 session_id\n",
    "                              FROM sygic_filt_05_06 as points, melb_urban_area_buffer as bndry\n",
    "                                WHERE \n",
    "                                    bndry.geom && points.geom AND \n",
    "                                    ST_Contains(bndry.geom,points.geom) \n",
    "                                    AND local_time > '2016-05-06 06:00:00'\n",
    "                                    AND local_time < '2016-05-06 12:45:00'\n",
    "                                    ;\n",
    "                        \"\"\",con=engine)\n",
    "\n",
    "# Outfiles \n",
    "print (df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load road network and create network \n",
    "street_network = 'C:/Data/road_network_main_prj.shp'\n",
    "# Set segmment ID - OBJECTID \n",
    "seg_info = mm.getSegmentInfo(street_network)\n",
    "seg_geom = mm.getSegmentShapes(street_network)\n",
    "graph = mm.getNetworkGraph(street_network, seg_info[1])\n",
    "endpoints = seg_info[0]\n",
    "length = seg_info[1]\n",
    "# Create a spatial index for the road network\n",
    "idx = mm.buildRTree(street_network)\n",
    "\n",
    "print ('Network data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Expected Traffic Conditions\n",
    "\n",
    "p1 = 0.5\n",
    "p2 = 0.4\n",
    "v_min = 3.0\n",
    "#pd.isnull(row['median_freq'])\n",
    "def traffic_cond(row):\n",
    "    \n",
    "    if row['median_freq_y'] < 4 or (row.isnull().sum()) > 3:\n",
    "        return 'Absent/Not Sufficient'\n",
    "    \n",
    "    if row['median_speed_y'] >= (p1* row['speed_lim_x']):\n",
    "        return 'Flowing'\n",
    "    \n",
    "    if  row['median_speed_y'] < (p1* row['speed_lim_x']):\n",
    "        \n",
    "        if (row['median_speed_y'] <= (p2* row['speed_lim_x'])) & (row['median_speed_y'] > v_min):\n",
    "            \n",
    "            return 'Very Slow'\n",
    "        \n",
    "        if (row['median_speed_y'] <= v_min) & (row['median_freq_y'] >= 4):\n",
    "            \n",
    "            return 'Blocked'\n",
    "        else:\n",
    "            return 'Slow'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "def traffic_change(row):\n",
    "    if (row['traffic'] == 'Slow') & (row['traffic_expected_cond'] == 'Flowing')\n",
    "        & (row['median_speed'] < (row['speed_expected']- row['expected_std']):\n",
    "        return 1\n",
    "    if (row['traffic'] == 'Very Slow') & (row['traffic_expected_cond'] == 'Flowing' or row['traffic_expected_cond']=='Slow'):\n",
    "        return 1\n",
    "    if (row['traffic'] == 'Blocked') & (row['traffic_expected_cond'] == 'Flowing' \n",
    "                                      or row['traffic_expected_cond']=='Slow'\n",
    "                                      or row['traffic_expected_cond'] == 'Very Slow'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7201\n",
      "5073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(510079, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILTER DATA \n",
    "\n",
    "# Group data by session_id and sort by time\n",
    "group = df.groupby(\"session_id\")\n",
    "sort_function = lambda x: x.sort_values('local_time', ascending = True)\n",
    "df_sorted = group.apply(sort_function)\n",
    "df_sorted.rename(columns = {'session_id': 'session_id_traj'}, inplace = True)\n",
    "\n",
    "# Compute speed, detla time and distance for each session \n",
    "dx = (df_sorted['x'] - df_sorted.groupby('session_id_traj')['x'].shift())\n",
    "dy = (df_sorted['y'] - df_sorted.groupby('session_id_traj')['y'].shift())\n",
    "dt = (df_sorted['local_time'] - df_sorted.groupby('session_id_traj')['local_time'].shift())\n",
    "df_sorted['dist'] = (np.sqrt(dx**2 + dy**2))/1000 # distance in km \n",
    "df_sorted['time_dif'] = dt.astype('timedelta64[s]') # time difference in seconds\n",
    "df_sorted['speed_calc'] = df_sorted['dist']/(df_sorted['time_dif']/3600)  #speed in km/hr \n",
    "df_sorted.loc[df_sorted['speed_calc'] > 120, 'speed_calc'] = 120\n",
    "df_sorted.loc[(df_sorted['time_dif'] > 10), 'speed_calc'] = np.nan\n",
    "\n",
    "# Filter outliers in sessions/trajectories BY speed values and total distance per trajectory\n",
    "traj = df_sorted.groupby(\"session_id_traj\")\n",
    "summary_stats = traj['speed_calc'].describe()\n",
    "speed_quantile = summary_stats['mean'].quantile(.25)\n",
    "\n",
    "\n",
    "# DROP NA sessions \n",
    "keep_sessions = (summary_stats.dropna(subset = ['max','std','min'])).index.values.tolist()\n",
    "print len(keep_sessions)\n",
    "df_sorted = df_sorted[df_sorted['session_id_traj'].isin(keep_sessions)]\n",
    "# DROP Trajectories with total distance less than 50 metres\n",
    "sessions_dist = df_sorted.groupby('session_id_traj')['dist'].agg(['sum','count','max','min'])\n",
    "keep_sessions = (sessions_dist.loc[sessions_dist['sum'] > 0.050]).index.values.tolist()\n",
    "print len(keep_sessions)\n",
    "df_sorted = df_sorted[df_sorted['session_id_traj'].isin(keep_sessions)]\n",
    "# Get coordinates in a tuple\n",
    "np.float32(0).item()\n",
    "df_sorted[\"coords_xy\"] = list(zip(df_sorted.x,df_sorted.y))\n",
    "df_sorted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9122\n"
     ]
    }
   ],
   "source": [
    "print len(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "local_time         datetime64[ns]\n",
       "x                         float64\n",
       "y                         float64\n",
       "speed                     float64\n",
       "session_id_traj            object\n",
       "dist                      float64\n",
       "time_dif                  float64\n",
       "speed_calc                float64\n",
       "coords_xy                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine time range\n",
    "dates = pd.date_range('2016-05-06 6:00:00', '2016-05-06 07:00:00', freq='10 min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                int64\n",
       "FID_x                     int64\n",
       "full_name_x              object\n",
       "t_hierarch_x             object\n",
       "dist_m_x                  int64\n",
       "OBJECTID                float64\n",
       "Zone_x                   object\n",
       "speed_lim_x               int64\n",
       "median_speed_weekday    float64\n",
       "std_weekday             float64\n",
       "speed_mon               float64\n",
       "speed_tue               float64\n",
       "speed_wed               float64\n",
       "speed_thu               float64\n",
       "speed_fri               float64\n",
       "freq_weekday            float64\n",
       "std_freq_weekday        float64\n",
       "freq_mon                float64\n",
       "freq_tue                float64\n",
       "freq_wed                float64\n",
       "freq_thu                float64\n",
       "freq_fri                float64\n",
       "exp_traffic_weekdays     object\n",
       "exp_traffic_mon          object\n",
       "exp_traffic_tue          object\n",
       "exp_traffic_wed          object\n",
       "exp_traffic_thu          object\n",
       "exp_traffic_fri          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = 'C:/sygic/output_files/temp_map_matching/'\n",
    "#Load expected traffic condition data for correspondent time period \n",
    "traff_condition = pd.read_csv('C:/sygic/output_files/expected_traffic_conditions/Weekdays_am_peak_traffic_cond.csv',sep=',')\n",
    "traff_condition.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traff_sub = traff_condition[['OBJECTID','full_name_x','Zone_x','speed_lim_x','median_speed_weekday','std_weekday',\n",
    "                             'speed_fri','freq_weekday','exp_traffic_weekdays','exp_traffic_fri']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>full_name_x</th>\n",
       "      <th>Zone_x</th>\n",
       "      <th>speed_lim_x</th>\n",
       "      <th>median_speed_weekday</th>\n",
       "      <th>std_weekday</th>\n",
       "      <th>speed_fri</th>\n",
       "      <th>freq_weekday</th>\n",
       "      <th>exp_traffic_weekdays</th>\n",
       "      <th>exp_traffic_fri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>EASTERN FREEWAY</td>\n",
       "      <td>Outer Metro Melbourne</td>\n",
       "      <td>100</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>7.119793</td>\n",
       "      <td>92.758988</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Flowing</td>\n",
       "      <td>Flowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>EASTERN FREEWAY</td>\n",
       "      <td>Outer Metro Melbourne</td>\n",
       "      <td>100</td>\n",
       "      <td>85.124376</td>\n",
       "      <td>6.565197</td>\n",
       "      <td>89.527012</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Flowing</td>\n",
       "      <td>Flowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>DANDENONG-HASTINGS ROAD</td>\n",
       "      <td>Outer Metro Melbourne</td>\n",
       "      <td>100</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>9.874898</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Flowing</td>\n",
       "      <td>Flowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>DANDENONG-HASTINGS ROAD</td>\n",
       "      <td>Outer Metro Melbourne</td>\n",
       "      <td>90</td>\n",
       "      <td>79.154531</td>\n",
       "      <td>10.064538</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Flowing</td>\n",
       "      <td>Flowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>KINGS-WEST GATE OUT RAMP ON</td>\n",
       "      <td>Inner Metro Melbourne</td>\n",
       "      <td>80</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>13.507368</td>\n",
       "      <td>73.978791</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Flowing</td>\n",
       "      <td>Flowing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID                  full_name_x                 Zone_x  speed_lim_x  \\\n",
       "0       1.0              EASTERN FREEWAY  Outer Metro Melbourne          100   \n",
       "1       2.0              EASTERN FREEWAY  Outer Metro Melbourne          100   \n",
       "2       3.0      DANDENONG-HASTINGS ROAD  Outer Metro Melbourne          100   \n",
       "3       4.0      DANDENONG-HASTINGS ROAD  Outer Metro Melbourne           90   \n",
       "4       5.0  KINGS-WEST GATE OUT RAMP ON  Inner Metro Melbourne           80   \n",
       "\n",
       "   median_speed_weekday  std_weekday  speed_fri  freq_weekday  \\\n",
       "0             89.500000     7.119793  92.758988          31.0   \n",
       "1             85.124376     6.565197  89.527012          34.0   \n",
       "2             82.000000     9.874898  86.000000           4.0   \n",
       "3             79.154531    10.064538  83.000000           6.0   \n",
       "4             72.000000    13.507368  73.978791           3.0   \n",
       "\n",
       "  exp_traffic_weekdays exp_traffic_fri  \n",
       "0              Flowing         Flowing  \n",
       "1              Flowing         Flowing  \n",
       "2              Flowing         Flowing  \n",
       "3              Flowing         Flowing  \n",
       "4              Flowing         Flowing  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traff_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016-05-06 15:00:00\n",
      "(14147, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2157 matched segments\n",
      "174 total mapped sessions\n",
      "197 broken or unmappable sessions\n",
      "0:43:33.567000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2016-05-06 15:10:00\n",
      "(15581, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2315 matched segments\n",
      "195 total mapped sessions\n",
      "219 broken or unmappable sessions\n",
      "0:44:16.022000\n",
      "2 2016-05-06 15:20:00\n",
      "(15699, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2607 matched segments\n",
      "221 total mapped sessions\n",
      "229 broken or unmappable sessions\n",
      "0:45:09.925000\n",
      "3 2016-05-06 15:30:00\n",
      "(17555, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2489 matched segments\n",
      "269 total mapped sessions\n",
      "293 broken or unmappable sessions\n",
      "0:45:55.269000\n",
      "4 2016-05-06 15:40:00\n",
      "(16406, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2462 matched segments\n",
      "237 total mapped sessions\n",
      "259 broken or unmappable sessions\n",
      "0:46:37.487000\n",
      "5 2016-05-06 15:50:00\n",
      "(17741, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2780 matched segments\n",
      "235 total mapped sessions\n",
      "258 broken or unmappable sessions\n",
      "0:47:08.017000\n",
      "6 2016-05-06 16:00:00\n",
      "(18033, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "3118 matched segments\n",
      "259 total mapped sessions\n",
      "234 broken or unmappable sessions\n",
      "0:47:55.944000\n",
      "7 2016-05-06 16:10:00\n",
      "(17428, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2594 matched segments\n",
      "230 total mapped sessions\n",
      "257 broken or unmappable sessions\n",
      "0:48:44.616000\n",
      "8 2016-05-06 16:20:00\n",
      "(15739, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2567 matched segments\n",
      "205 total mapped sessions\n",
      "226 broken or unmappable sessions\n",
      "0:49:36.659000\n",
      "9 2016-05-06 16:30:00\n",
      "(15489, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2565 matched segments\n",
      "215 total mapped sessions\n",
      "221 broken or unmappable sessions\n",
      "0:50:16.396000\n",
      "10 2016-05-06 16:40:00\n",
      "(15686, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2287 matched segments\n",
      "200 total mapped sessions\n",
      "230 broken or unmappable sessions\n",
      "0:50:53.146000\n",
      "11 2016-05-06 16:50:00\n",
      "(16101, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2333 matched segments\n",
      "218 total mapped sessions\n",
      "245 broken or unmappable sessions\n",
      "0:51:34.255000\n",
      "12 2016-05-06 17:00:00\n",
      "(16043, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2562 matched segments\n",
      "229 total mapped sessions\n",
      "234 broken or unmappable sessions\n",
      "0:52:34.392000\n",
      "13 2016-05-06 17:10:00\n",
      "(18043, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "3150 matched segments\n",
      "238 total mapped sessions\n",
      "225 broken or unmappable sessions\n",
      "0:53:38.852000\n",
      "14 2016-05-06 17:20:00\n",
      "(19326, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "3099 matched segments\n",
      "255 total mapped sessions\n",
      "243 broken or unmappable sessions\n",
      "0:54:49.944000\n",
      "15 2016-05-06 17:30:00\n",
      "(18758, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2823 matched segments\n",
      "230 total mapped sessions\n",
      "240 broken or unmappable sessions\n",
      "0:55:55.584000\n",
      "16 2016-05-06 17:40:00\n",
      "(16562, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2826 matched segments\n",
      "222 total mapped sessions\n",
      "228 broken or unmappable sessions\n",
      "0:57:13.141000\n",
      "17 2016-05-06 17:50:00\n",
      "(17878, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "3179 matched segments\n",
      "232 total mapped sessions\n",
      "221 broken or unmappable sessions\n",
      "0:58:44.744000\n",
      "18 2016-05-06 18:00:00\n",
      "(17474, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2901 matched segments\n",
      "226 total mapped sessions\n",
      "223 broken or unmappable sessions\n",
      "0:59:37.778000\n",
      "19 2016-05-06 18:10:00\n",
      "(17085, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2903 matched segments\n",
      "195 total mapped sessions\n",
      "217 broken or unmappable sessions\n",
      "1:00:31.106000\n",
      "20 2016-05-06 18:20:00\n",
      "(16721, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "3050 matched segments\n",
      "197 total mapped sessions\n",
      "199 broken or unmappable sessions\n",
      "1:01:34.854000\n",
      "21 2016-05-06 18:30:00\n",
      "(14511, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2769 matched segments\n",
      "181 total mapped sessions\n",
      "216 broken or unmappable sessions\n",
      "1:02:22.077000\n",
      "22 2016-05-06 18:40:00\n",
      "(14296, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2628 matched segments\n",
      "207 total mapped sessions\n",
      "194 broken or unmappable sessions\n",
      "1:03:15.549000\n",
      "23 2016-05-06 18:50:00\n",
      "(14356, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2296 matched segments\n",
      "158 total mapped sessions\n",
      "203 broken or unmappable sessions\n",
      "1:04:01.550000\n",
      "24 2016-05-06 19:00:00\n",
      "(12689, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2476 matched segments\n",
      "166 total mapped sessions\n",
      "184 broken or unmappable sessions\n",
      "1:04:47.026000\n",
      "25 2016-05-06 19:10:00\n",
      "(11667, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "1586 matched segments\n",
      "119 total mapped sessions\n",
      "199 broken or unmappable sessions\n",
      "1:05:29.126000\n",
      "26 2016-05-06 19:20:00\n",
      "(11050, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "1906 matched segments\n",
      "122 total mapped sessions\n",
      "176 broken or unmappable sessions\n",
      "1:06:05.409000\n",
      "27 2016-05-06 19:30:00\n",
      "(11163, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "1725 matched segments\n",
      "125 total mapped sessions\n",
      "169 broken or unmappable sessions\n",
      "1:06:44.457000\n",
      "28 2016-05-06 19:40:00\n",
      "(10801, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2364 matched segments\n",
      "115 total mapped sessions\n",
      "169 broken or unmappable sessions\n",
      "1:07:22.678000\n",
      "29 2016-05-06 19:50:00\n",
      "(10253, 9)\n",
      "Map matched done!\n",
      "Summary:\n",
      "-------------------------------------\n",
      "2274 matched segments\n",
      "106 total mapped sessions\n",
      "142 broken or unmappable sessions\n",
      "1:07:57.250000\n",
      "30 2016-05-06 20:00:00\n",
      "No matching roads\n"
     ]
    }
   ],
   "source": [
    "# Map matching process for each time sample range (10 min)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i, time in enumerate(dates):\n",
    "    \n",
    "    try:\n",
    "        sample = ''.join(['sample_',str(i),'_','time','.csv'])\n",
    "        print sample \n",
    "        df_sub = df_sorted.loc[(df_sorted['local_time'] > dates[i]) & (df_sorted['local_time'] < dates[i+1])]\n",
    "        print df_sub.shape\n",
    "        \n",
    "        with open(csv_input, 'r') as input_track:\n",
    "        \n",
    "            track = csv.reader(input_track, delimiter=',')\n",
    "            header_line = next(track)\n",
    "            seg_count_list = []\n",
    "            speed_count = defaultdict(list)\n",
    "            seg_speed_avg = {}\n",
    "            counter = 0\n",
    "            counter_sessions = 0\n",
    "            \n",
    "            for key, group in itertools.groupby(track, key=lambda x: x[6]):\n",
    "                try:\n",
    "                    indiv_track = []\n",
    "                    speed_track = [float(0)]\n",
    "                    #print key\n",
    "                    #print \"------------------\"\n",
    "                    for p in group:\n",
    "                    # x and y coordinates\n",
    "                        indiv_track.append((float(p[3]), float(p[4])))\n",
    "                        if p[9] not in (None, \"\"):\n",
    "                            speed_track.append(float(p[9]))\n",
    "                    ##Map matching algorithm\n",
    "                    opt = mm.mapMatch(indiv_track, seg_info, graph, idx, seg_geom,\n",
    "                                       500, 400, 50)\n",
    "                    #Create list of all matched segments\n",
    "                    for seg in opt:\n",
    "                        seg_count_list.append(seg)\n",
    "                    #Clean the path (remove double segments and crossings, etc.)\n",
    "                    opt_clean = mm.cleanPath(opt, endpoints)\n",
    "                    #Append speed value for matched segment\n",
    "                    for segment, value in itertools.izip(opt, speed_track):\n",
    "                        if segment in opt_clean:\n",
    "                            speed_count[segment].append(value)\n",
    "\n",
    "                    counter_sessions +=1\n",
    "                except:\n",
    "                    counter += 1\n",
    "\n",
    "            #Calculate segment frequency\n",
    "            seg_freq = {x: seg_count_list.count(x) for x in seg_count_list}\n",
    "            #Calculate average speed for each segment\n",
    "            for items in speed_count.items():\n",
    "                seg_speed_avg[items[0]] = sum(items[-1])/len(items[-1])\n",
    "        \n",
    "            print (\"Map matched done!\")\n",
    "            print (\"Summary:\")\n",
    "            print (\"-------------------------------------\")\n",
    "            print (\"%d matched segments\" %(len(seg_freq.keys())))\n",
    "            print (\"%d total mapped sessions\" %(counter_sessions))\n",
    "            print (\"%d broken or unmappable sessions\" %(counter))\n",
    "            print (datetime.now() - startTime)\n",
    "\n",
    "            #Evaluate differences\n",
    "            \n",
    "            freq = pd.DataFrame(seg_freq.items())\n",
    "            freq.rename(columns={0: 'OBJECTID', 1: 'median_freq_y'}, inplace=True)\n",
    "            speed = pd.DataFrame(seg_speed_avg.items())\n",
    "            speed.rename(columns={0: 'OBJECTID', 1: 'median_speed_y'}, inplace=True)\n",
    "            segment = freq.join(speed.set_index('OBJECTID'), on = 'OBJECTID')\n",
    "    \n",
    "            df_traffic = traff_sub.merge(segment, on='OBJECTID',how='left')\n",
    "            df_traffic['traffic'] = df_traffic.apply(lambda row: traffic_cond(row),axis=1)\n",
    "            df_traffic['BIN'] = df_traffic.apply(lambda row: traffic_change(row),axis=1)\n",
    "            \n",
    "            df_change = df_traffic.loc[df_traffic['BIN'] == 1]\n",
    "            df_change['timestamp'] = time\n",
    "            \n",
    "            dfs.append(df_change)\n",
    "            \n",
    "    except:\n",
    "        print \"No matching roads\"\n",
    "    \n",
    "masterDF = pd.concat(dfs, ignore_index=True)\n",
    "masterDF.to_csv('C:/Data/Output_files/Friday5_pm_peak_changes.csv',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2699, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterDF.shape\n",
    "\n",
    "masterDF.to_csv('C:/Data/Output_files/Friday5_am_peak_changes.csv',encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
