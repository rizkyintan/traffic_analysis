{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f84f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy.spatial import KDTree\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import DataFrame\n",
    "import time\n",
    "import numpy as np\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971acbf5",
   "metadata": {},
   "source": [
    "## Useful support function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce8f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(data):\n",
    "    # Ambil baris pertama dari DataFrame\n",
    "    first_row = data.iloc[0]\n",
    "\n",
    "    # Ambil nilai latitude dan longitude dari baris pertama\n",
    "    latitude = first_row['latitude']\n",
    "    longitude = first_row['longitude']\n",
    "    \n",
    "    m = folium.Map(location=[latitude, longitude], zoom_start=25)\n",
    "\n",
    "    # Add CircleMarkers for each point\n",
    "    for index, row in data.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "            radius=5,  # Marker size\n",
    "            color=\"blue\",  # Marker color\n",
    "            fill=True,\n",
    "            fill_color=\"blue\",  # Fill color of the marker\n",
    "            fill_opacity=0.7,  # Opacity of the marker fill\n",
    "            popup=f\"User ID: {row['maid']}<br>Latitude: {row['latitude']}<br>Longitude: {row['longitude']}\",\n",
    "        ).add_to(m)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7cb7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivot(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df_pivot = df['maid'].groupby(df['timestamp'].dt.date).value_counts()\n",
    "    pivot = df_pivot.unstack().fillna(0).astype(int)\n",
    "\n",
    "    total_counts = pivot.sum(axis=0)\n",
    "    sorted_columns = total_counts.sort_values(ascending=False).index\n",
    "    pivot_sorted = pivot[sorted_columns]\n",
    "    return pivot_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8081e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line(data):\n",
    "    data = data.to_crs('EPSG:4326')\n",
    "    data = data['geometry']\n",
    "    # Buat peta dengan lokasi awal berdasarkan rata-rata koordinat dari data linestring\n",
    "    avg_lat = data.apply(lambda x: x.centroid.y).mean()\n",
    "    avg_lon = data.apply(lambda x: x.centroid.x).mean()\n",
    "    m = folium.Map(location=[avg_lat, avg_lon], zoom_start=15)\n",
    "\n",
    "    # Tambahkan polyline untuk setiap linestring\n",
    "    for linestring in data:\n",
    "        coordinates = [(lat, lon) for lon, lat in linestring.coords]\n",
    "        folium.PolyLine(locations=coordinates, color='purple', weight=8, opacity=0.7).add_to(m)\n",
    "\n",
    "    # Tambahkan GeoJson dari data GeoPandas\n",
    "    folium.GeoJson(data.to_json(), name='Garis Jalan').add_to(m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87def482",
   "metadata": {},
   "source": [
    "## Modified process_group function to ensure each GPS data addition follows the node sequence of the road network graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641d5083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>adjusted_longitude</th>\n",
       "      <th>adjusted_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00012afc-6daf-461f-96a8-181e5af69db9</td>\n",
       "      <td>-7.800291</td>\n",
       "      <td>110.364998</td>\n",
       "      <td>2021-12-01 17:54:11</td>\n",
       "      <td>110.364996</td>\n",
       "      <td>-7.800210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00012afc-6daf-461f-96a8-181e5af69db9</td>\n",
       "      <td>-7.800300</td>\n",
       "      <td>110.364998</td>\n",
       "      <td>2021-12-01 17:54:22</td>\n",
       "      <td>110.364996</td>\n",
       "      <td>-7.800210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00012afc-6daf-461f-96a8-181e5af69db9</td>\n",
       "      <td>-7.800300</td>\n",
       "      <td>110.364998</td>\n",
       "      <td>2021-12-01 17:54:22</td>\n",
       "      <td>110.364996</td>\n",
       "      <td>-7.800210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000136a6-c76e-4f76-841d-1329727ad906</td>\n",
       "      <td>-7.785730</td>\n",
       "      <td>110.366640</td>\n",
       "      <td>2021-12-06 18:38:17</td>\n",
       "      <td>110.366636</td>\n",
       "      <td>-7.785796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000136a6-c76e-4f76-841d-1329727ad906</td>\n",
       "      <td>-7.785730</td>\n",
       "      <td>110.366638</td>\n",
       "      <td>2021-12-08 12:08:42</td>\n",
       "      <td>110.366636</td>\n",
       "      <td>-7.785796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   maid  latitude   longitude  \\\n",
       "0  00012afc-6daf-461f-96a8-181e5af69db9 -7.800291  110.364998   \n",
       "1  00012afc-6daf-461f-96a8-181e5af69db9 -7.800300  110.364998   \n",
       "2  00012afc-6daf-461f-96a8-181e5af69db9 -7.800300  110.364998   \n",
       "3  000136a6-c76e-4f76-841d-1329727ad906 -7.785730  110.366640   \n",
       "4  000136a6-c76e-4f76-841d-1329727ad906 -7.785730  110.366638   \n",
       "\n",
       "             timestamp  adjusted_longitude  adjusted_latitude  \n",
       "0  2021-12-01 17:54:11          110.364996          -7.800210  \n",
       "1  2021-12-01 17:54:22          110.364996          -7.800210  \n",
       "2  2021-12-01 17:54:22          110.364996          -7.800210  \n",
       "3  2021-12-06 18:38:17          110.366636          -7.785796  \n",
       "4  2021-12-08 12:08:42          110.366636          -7.785796  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the gps CSV file into a DataFrame\n",
    "gps = pd.read_csv('./filter4_20m_60min_immobility_malar_des.csv')\n",
    "gps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54fadd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified process_group function to ensure each GPS data addition follows the node sequence of the road network graph\n",
    "def process_group(group, graph):\n",
    "    # Map Matching (Assumed to be Accurate)\n",
    "    mapped_points_group = group[['adjusted_longitude', 'adjusted_latitude']].values\n",
    "    \n",
    "    # Initialize the resulting path and timestamps\n",
    "    resulting_path_group = [tuple(mapped_points_group[0])]\n",
    "    new_timestamps = [group['timestamp'].values[0]]\n",
    "    \n",
    "    prev_node = tuple(mapped_points_group[0])\n",
    "    \n",
    "    for i in range(1, len(mapped_points_group)):\n",
    "        current_node = tuple(mapped_points_group[i])\n",
    "        \n",
    "        # Use Shortest Path on Road Graph to get the sequence of nodes from prev_node to current_node\n",
    "        path = find_path_on_graph(graph, prev_node, current_node)\n",
    "        \n",
    "        # Extend the resulting path with nodes from the graph (no points outside the graph)\n",
    "        # This also ensures that the added GPS data follows the node sequence of the road network graph\n",
    "        resulting_path_group.extend(path[1:])\n",
    "        \n",
    "        # Time Interpolation (Assuming the path only contains points from the graph)\n",
    "        if len(path) > 2:\n",
    "            time_start = group['timestamp'].values[i-1]\n",
    "            time_end = group['timestamp'].values[i]\n",
    "            time_duration = (time_end - time_start) // np.timedelta64(1, 's')\n",
    "            \n",
    "            num_new_points = len(path) - 2\n",
    "            time_interval = time_duration // num_new_points if num_new_points > 0 else 0\n",
    "            \n",
    "            # Adding validation for interpolated timestamps\n",
    "            if time_interval < 0:\n",
    "                print(\"Negative time interval found, skipping this part.\")\n",
    "                continue\n",
    "            \n",
    "            interpolated_timestamps = [time_start + np.timedelta64(int(time_interval * j), 's') for j in range(1, num_new_points + 1)]\n",
    "            new_timestamps.extend(interpolated_timestamps)\n",
    "        \n",
    "        # Append the timestamp of the current node\n",
    "        new_timestamps.append(group['timestamp'].values[i])\n",
    "        \n",
    "        # Update prev_node for the next iteration\n",
    "        prev_node = current_node\n",
    "    \n",
    "    # Use the original 'maid' values\n",
    "    maids = list(group['maid'].values) + [group['maid'].values[-1]] * (len(resulting_path_group) - len(group))\n",
    "    \n",
    "    return [(maids[i], point[1], point[0], new_timestamps[i]) for i, point in enumerate(resulting_path_group)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32582b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                 | 0/72781 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/parallel.py:825\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkham/lib/python3.10/queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m gps\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaid\u001b[39m\u001b[38;5;124m'\u001b[39m, gps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate])\n\u001b[1;32m      6\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 7\u001b[0m processed_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrouped_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m flattened_results \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m processed_results \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n",
      "File \u001b[0;32m~/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1048\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1049\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/parallel.py:836\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_effective_n_jobs\n\u001b[1;32m    834\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[0;32m--> 836\u001b[0m islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(islice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m gps\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaid\u001b[39m\u001b[38;5;124m'\u001b[39m, gps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate])\n\u001b[1;32m      6\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 7\u001b[0m processed_results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)(delayed(process_group)(group, \u001b[43mG\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m _, group \u001b[38;5;129;01min\u001b[39;00m tqdm(grouped_data))\n\u001b[1;32m      8\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m flattened_results \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m processed_results \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "# change format to datetime just to make sure\n",
    "gps['timestamp'] = pd.to_datetime(gps['timestamp'])\n",
    "\n",
    "grouped_data = gps.groupby(['maid', gps['timestamp'].dt.date])\n",
    "\n",
    "start = time.time()\n",
    "processed_results = Parallel(n_jobs=40)(delayed(process_group)(group, G) for _, group in tqdm(grouped_data))\n",
    "end = time.time()\n",
    "\n",
    "flattened_results = [item for sublist in processed_results for item in sublist]\n",
    "resulting_data = pd.DataFrame(flattened_results, columns=['maid', 'latitude', 'longitude', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The time of execution of above program is:\", (end - start) / 1000, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to CSV file\n",
    "resulting_data.to_csv(\"filter5_20m_60min_immobility_adjusted_malar_des.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6612e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c86cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
