{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.3.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"b7c116f4-7cae-4784-9e5f-9a60b60b9af6\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"ea87296b-9988-4db5-93f5-ed8e4f955f6b\":{\"version\":\"3.3.0\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"80081285a53c40c4a18593212cfca53b\",\"client_comm_id\":\"7863b48f1827452cbac0e0aa72ad1225\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"ea87296b-9988-4db5-93f5-ed8e4f955f6b\",\"roots\":{\"p1002\":\"b7c116f4-7cae-4784-9e5f-9a60b60b9af6\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import numpy as np\n",
    "import folium\n",
    "import movingpandas as mpd\n",
    "import shapely as shp\n",
    "import hvplot.pandas \n",
    "import geoviews\n",
    "import mapclassify\n",
    "import skmob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import KDTree\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from geopandas import GeoDataFrame, read_file\n",
    "from shapely.geometry import mapping, shape, Point, LineString, Polygon\n",
    "from datetime import datetime, timedelta\n",
    "from holoviews import opts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful support function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(data): # with maid\n",
    "    # Ambil baris pertama dari DataFrame\n",
    "    first_row = data.iloc[0]\n",
    "\n",
    "    # Ambil nilai latitude dan longitude dari baris pertama\n",
    "    latitude = first_row['latitude']\n",
    "    longitude = first_row['longitude']\n",
    "    \n",
    "    m = folium.Map(location=[latitude, longitude], zoom_start=25)\n",
    "\n",
    "    # Add CircleMarkers for each point\n",
    "    for index, row in data.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "            radius=5,  # Marker size\n",
    "            color=\"blue\",  # Marker color\n",
    "            fill=True,\n",
    "            fill_color=\"blue\",  # Fill color of the marker\n",
    "            fill_opacity=0.7,  # Opacity of the marker fill\n",
    "            popup=f\"User ID: {row['maid']}<br>Latitude: {row['latitude']}<br>Longitude: {row['longitude']}\",\n",
    "        ).add_to(m)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot_raw(data): # only lat, lon\n",
    "    # Ambil baris pertama dari DataFrame\n",
    "    first_row = data.iloc[0]\n",
    "\n",
    "    # Ambil nilai latitude dan longitude dari baris pertama\n",
    "    latitude = first_row['latitude']\n",
    "    longitude = first_row['longitude']\n",
    "    \n",
    "    m = folium.Map(location=[latitude, longitude], zoom_start=25)\n",
    "\n",
    "    # Add CircleMarkers for each point\n",
    "    for index, row in data.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "            radius=5,  # Marker size\n",
    "            color=\"blue\",  # Marker color\n",
    "            fill=True,\n",
    "            fill_color=\"blue\",  # Fill color of the marker\n",
    "            fill_opacity=0.7,  # Opacity of the marker fill\n",
    "            popup=f\"Latitude: {row['latitude']}<br>Longitude: {row['longitude']}\",\n",
    "        ).add_to(m)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivot(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df_pivot = df['maid'].groupby(df['timestamp'].dt.date).value_counts()\n",
    "    pivot = df_pivot.unstack().fillna(0).astype(int)\n",
    "\n",
    "    total_counts = pivot.sum(axis=0)\n",
    "    sorted_columns = total_counts.sort_values(ascending=False).index\n",
    "    pivot_sorted = pivot[sorted_columns]\n",
    "    return pivot_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line(data):\n",
    "    data = data.to_crs('EPSG:4326')\n",
    "    data = data['geometry']\n",
    "    # Buat peta dengan lokasi awal berdasarkan rata-rata koordinat dari data linestring\n",
    "    avg_lat = data.apply(lambda x: x.centroid.y).mean()\n",
    "    avg_lon = data.apply(lambda x: x.centroid.x).mean()\n",
    "    m = folium.Map(location=[avg_lat, avg_lon], zoom_start=15)\n",
    "\n",
    "    # Tambahkan polyline untuk setiap linestring\n",
    "    for linestring in data:\n",
    "        coordinates = [(lat, lon) for lon, lat in linestring.coords]\n",
    "        folium.PolyLine(locations=coordinates, color='purple', weight=8, opacity=0.7).add_to(m)\n",
    "\n",
    "    # Tambahkan GeoJson dari data GeoPandas\n",
    "    folium.GeoJson(data.to_json(), name='Garis Jalan').add_to(m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filter Area around Malioboro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_area(gps, road):\n",
    "    road_path = road\n",
    "    \n",
    "    tdf = skmob.TrajDataFrame.from_file(gps)\n",
    "    area_shape = gpd.read_file(road_path)\n",
    "    \n",
    "    gdf_gps = GeoDataFrame(tdf, geometry=gpd.points_from_xy(tdf['longitude'], tdf['latitude']))\n",
    "    filtered_data = gdf_gps[gdf_gps.geometry.within(area_shape.geometry.iloc[0])].copy()\n",
    "    \n",
    "    filtered_data['datetime_wib'] = pd.to_datetime(filtered_data['datetime_wib'])\n",
    "    filtered_data['tanggal'] = filtered_data['datetime_wib'].dt.date\n",
    "    \n",
    "    print(\"Filtering area succeed\")\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reverse geocoding data\n",
    "gps = '../../../DataTelkomsel/2021November/RGnovember2021.csv'\n",
    "road = './Malioboro_around/Shrink/clipping_boundary.geojson'\n",
    "\n",
    "filtered_data = filter_area(gps, road)\n",
    "filtered_data.to_csv('filter1_malas_nov.csv', index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing basic\n",
    "- Changed datetime_wib column -> timestamp\n",
    "- Convert data type timestamp to datetime\n",
    "- Get the required columns df[['maid', 'latitude', 'longitude', 'timestamp']]\n",
    "- Remove duplicate data based on the same maid and time\n",
    "- Sort data by maid and timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_gps_data(df):\n",
    "    # Step 1: Ubah nama kolom datetime_wib menjadi timestamp\n",
    "    df = df.rename(columns={'datetime_wib':'timestamp'})\n",
    "    \n",
    "    # Step 2: Konversi tipe data pada kolom timestamp menjadi datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Step 3: Ambil hanya kolom maid, latitude, longitude, dan timestamp\n",
    "    df_filtered = df[['maid', 'latitude', 'longitude', 'timestamp']]\n",
    "        \n",
    "    # Step 4: Hapus data duplikat utk data keseluruhan dan data duplikat utk maid dan timestamp yg sama \n",
    "    # (ga mgkn berada pada dua tmpt berbeda dalam satu waktu kan)\n",
    "    df_filtered = df_filtered.drop_duplicates(subset=['maid', 'timestamp'])\n",
    "    \n",
    "    # Step 5: Hapus data yang hanya memiliki 1 record data dalam 1 hari\n",
    "    df_filtered['date'] = df_filtered['timestamp'].dt.date\n",
    "    record_count_per_day = df_filtered.groupby(['maid', 'date']).size().reset_index(name='count')\n",
    "    multiple_records_per_day = record_count_per_day[record_count_per_day['count'] > 1]\n",
    "    df_filtered = pd.merge(df_filtered, multiple_records_per_day[['maid', 'date']], on=['maid', 'date'], how='inner')\n",
    "    df_filtered.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    # Step 6: Urutkan data berdasarkan maid dan timestamp\n",
    "    df_filtered = df_filtered.sort_values(by=['maid', 'timestamp'])\n",
    "    \n",
    "    # Step 7: Reset index\n",
    "    df_filtered.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read GPS data\n",
    "df = pd.read_csv('filter1_malas_nov.csv')\n",
    "\n",
    "# Do the process\n",
    "df_preprocessed = preprocess_gps_data(df)\n",
    "\n",
    "# Save the result\n",
    "df_preprocessed.to_csv('filter2_malas_nov.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter data points with radius <x radius meter from the road network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_area_around_road(gps_data, road_data, distance):\n",
    "    # Membuat GeoDataFrame dari data GPS\n",
    "    gdf_gps = gpd.GeoDataFrame(\n",
    "        gps_data,\n",
    "        geometry=gpd.points_from_xy(gps_data.longitude, gps_data.latitude),\n",
    "        crs=\"EPSG:4326\"  # WGS84 coordinate reference system\n",
    "    )\n",
    "\n",
    "    # Membuat GeoDataFrame dari data jaringan jalan\n",
    "    gdf_jalan = gpd.GeoDataFrame(\n",
    "        road_data,\n",
    "        geometry=road_data.geometry,\n",
    "        crs=\"EPSG:4326\"  # WGS84 coordinate reference system\n",
    "    )\n",
    "\n",
    "    # Mengubah sistem referensi koordinat jaringan jalan ke UTM (misalnya UTM zone 48S untuk Yogyakarta)\n",
    "    gdf_jalan = gdf_jalan.to_crs(\"EPSG:32748\")  # UTM zone 48S\n",
    "\n",
    "    # Buffer jaringan jalan sebesar 20 meter\n",
    "    buffered_jalan = gdf_jalan.buffer(distance)\n",
    "\n",
    "    # Gabungkan semua buffered jalan menjadi satu geometri\n",
    "    merged_buffer = buffered_jalan.unary_union\n",
    "\n",
    "    # Mengubah sistem referensi koordinat data GPS ke UTM\n",
    "    gdf_gps = gdf_gps.to_crs(\"EPSG:32748\")  # UTM zone 48S\n",
    "\n",
    "    # Membuat kolom baru untuk menyimpan jarak terdekat ke jalan\n",
    "    gdf_gps['closest_distance_to_road'] = gdf_gps.geometry.apply(lambda x: x.distance(merged_buffer))\n",
    "\n",
    "    # Mengambil data point yang jaraknya maksimal 20 meter dari jaringan jalan\n",
    "    data_point_terdekat = gdf_gps[gdf_gps['closest_distance_to_road'] <= distance]\n",
    "\n",
    "    return data_point_terdekat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the road data\n",
    "road = './Malioboro_around/Shrink/Malioboro_around_shrink_line.shp'\n",
    "area_shape = gpd.read_file(road)\n",
    "\n",
    "highway = ['living_street','residential','primary','primary_link','tertiary', 'secondary', 'unclassified', 'secondary_link', 'tertiary_link','track']\n",
    "area_vehicle = area_shape[area_shape['highway'].isin(highway)]\n",
    "area_vehicle = area_vehicle[['osm_id','oneway','name', 'highway', 'geometry']]\n",
    "area_vehicle.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data GPS and road data\n",
    "gps_data = pd.read_csv('filter2_malas_des.csv')\n",
    "road_data = area_vehicle\n",
    "\n",
    "# Do the process\n",
    "radius = 20 # change this to choose the radius from road network\n",
    "df_filtered = filter_area_around_road(gps_data, road_data, radius)\n",
    "\n",
    "# Save the result\n",
    "df_filtered.to_csv(f'filter3_{radius}m_malas_des.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Map matching with KDTree to mapping all gps points to the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For trial with small data\n",
    "data = pd.read_csv('./filter2_malar_des.csv')\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "gps = data[(data['maid'] == 'd9f515f4-1a78-442b-81c4-55bf5f253b91') & (data['timestamp'].dt.date == pd.to_datetime('2021-12-06').date())]\n",
    "gps.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the dataframe from the previous process\n",
    "radius = 5 # change this to choose the radius from road network\n",
    "gps = pd.read_csv(f'filter3_{radius}m_malas_des.csv')\n",
    "\n",
    "# Reading the road CSV file into a DataFrame\n",
    "road = pd.read_csv('./expanded_road_df_DIY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graph from Road Network Data\n",
    "G = nx.Graph()\n",
    "for index, row in road.iterrows():\n",
    "    G.add_edge((row['start_x'], row['start_y']), (row['end_x'], row['end_y']), weight=1, name=row['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Matching with KDTree untuk menarik data yg tidak di jalan menjadi berada di jalan\n",
    "sorted_gps = gps.sort_values(by=['maid', 'timestamp'])\n",
    "node_list = list(G.nodes())\n",
    "\n",
    "tree = KDTree(node_list)\n",
    "distances, indices = tree.query(sorted_gps[['longitude', 'latitude']].values)\n",
    "all_mapped_points_kdtree = [node_list[index] for index in indices]\n",
    "\n",
    "sorted_gps['adjusted_longitude'] = [point[0] for point in all_mapped_points_kdtree]\n",
    "sorted_gps['adjusted_latitude'] = [point[1] for point in all_mapped_points_kdtree]\n",
    "sorted_gps['timestamp'] = pd.to_datetime(sorted_gps['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result\n",
    "sorted_gps.to_csv('filter4_5m_malas_des.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sorted_gps\n",
    "a = data[(data['maid'] == 'd9f515f4-1a78-442b-81c4-55bf5f253b91') & (data['timestamp'].dt.date == pd.to_datetime('2021-12-06').date())]\n",
    "# create_plot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter immobility data with mas Arkham algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_immobility_arkham(name, group):\n",
    "    filtered_data = []\n",
    "    group = group.sort_values('timestamp')\n",
    "    prev_row = None\n",
    "    immobile_start_row = None\n",
    "\n",
    "    for i, row in group.iterrows():\n",
    "        if prev_row is not None:\n",
    "            if row['adjusted_latitude'] == prev_row['adjusted_latitude'] and row['adjusted_longitude'] == prev_row['adjusted_longitude']:\n",
    "                if immobile_start_row is None:\n",
    "                    immobile_start_row = prev_row\n",
    "            else:\n",
    "                if immobile_start_row is not None:\n",
    "                    filtered_data.append(immobile_start_row)\n",
    "                    immobile_start_row = None\n",
    "                filtered_data.append(row)\n",
    "\n",
    "        prev_row = row\n",
    "\n",
    "    if immobile_start_row is not None:\n",
    "        filtered_data.append(immobile_start_row)\n",
    "    else:\n",
    "        if prev_row is not None:\n",
    "            filtered_data.append(prev_row)\n",
    "\n",
    "    return pd.DataFrame(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_immobility_parallel(data):\n",
    "    data['date'] = pd.to_datetime(data['timestamp']).dt.date\n",
    "    grouped = data.groupby(['maid', 'date'])\n",
    "    results = Parallel(n_jobs=40)(delayed(filter_immobility_arkham)(name, group) for name, group in tqdm(grouped))\n",
    "    return pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data GPS and road data\n",
    "gps_data = pd.read_csv('filter4_5m_malas_des.csv')\n",
    "\n",
    "# Do the process\n",
    "compressed_data = filter_immobility_parallel(gps_data)\n",
    "\n",
    "# Save the result\n",
    "compressed_data.to_csv('filter5_5m_malas_des.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = compressed_data\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "a = data[(data['maid'] == 'd9f515f4-1a78-442b-81c4-55bf5f253b91') & (data['timestamp'].dt.date == pd.to_datetime('2021-12-06').date())]\n",
    "create_plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adjusted path also based on mas Arkham algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read shp shape data for adjusted path\n",
    "road_shp = './Malioboro_around/Shrink/Malioboro_around_shrink_line.shp'\n",
    "road_gdf = gpd.read_file(road_shp)\n",
    "road_df = pd.DataFrame(road_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat ulang graph berarah dengan memperbaiki pendekatan\n",
    "G_corrected = nx.MultiDiGraph()\n",
    "\n",
    "# Fungsi untuk menambahkan edge dengan memecah geometri menjadi setiap segmen dan menyimpan geometri\n",
    "def add_edges_corrected(geometry_str, oneway=False):\n",
    "    if isinstance(geometry_str, str):\n",
    "        # Mengubah string geometry menjadi objek LINESTRING\n",
    "        linestring = shapely.wkt.loads(geometry_str)\n",
    "    else:\n",
    "        linestring = geometry_str\n",
    "        \n",
    "    # Mendapatkan semua koordinat dalam linestring\n",
    "    coords = list(linestring.coords)\n",
    "    \n",
    "    # Iterasi melalui setiap pasangan koordinat untuk menambahkan edge\n",
    "    for i in range(len(coords) - 1):\n",
    "        start_point, end_point = coords[i], coords[i + 1]\n",
    "        segment_geometry = LineString([start_point, end_point])\n",
    "        G_corrected.add_edge(start_point, end_point, geometry=mapping(segment_geometry))\n",
    "        if not oneway:  # Jika bukan jalan satu arah, tambahkan edge terbalik dan salin geometrinya\n",
    "            G_corrected.add_edge(end_point, start_point, geometry=mapping(segment_geometry))\n",
    "\n",
    "# Menyesuaikan penanganan kolom 'oneway' untuk memastikan akurasi\n",
    "for idx, row in road_df.iterrows():\n",
    "    oneway = row['oneway'] == 'yes' or row['oneway'] == 'true'  # Menganggap 'yes' atau 'true' sebagai jalan satu arah\n",
    "    add_edges_corrected(row['geometry'], oneway)\n",
    "\n",
    "# Informasi dasar tentang graph yang telah diperbaiki\n",
    "info_corrected = {\n",
    "    'number_of_nodes': G_corrected.number_of_nodes(),\n",
    "    'number_of_edges': G_corrected.number_of_edges(),\n",
    "}\n",
    "\n",
    "info_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghitung bearing (arah) antara dua titik\n",
    "def calculate_bearing(lat1, lon1, lat2, lon2):\n",
    "    start_lat = np.radians(lat1)\n",
    "    start_lng = np.radians(lon1)\n",
    "    end_lat = np.radians(lat2)\n",
    "    end_lng = np.radians(lon2)\n",
    "    \n",
    "    d_long = end_lng - start_lng\n",
    "    d_phi = np.log(np.tan(end_lat/2.0 + np.pi/4.0) / np.tan(start_lat/2.0 + np.pi/4.0))\n",
    "    \n",
    "    if abs(d_long) > np.pi:\n",
    "        if d_long > 0.0:\n",
    "            d_long = -(2.0 * np.pi - d_long)\n",
    "        else:\n",
    "            d_long = (2.0 * np.pi + d_long)\n",
    "    \n",
    "    bearing = (np.degrees(np.arctan2(d_long, d_phi)) + 360.0) % 360.0\n",
    "    return bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mencari edge terdekat yang sesuai dengan arah perjalanan\n",
    "def find_nearest_edge_with_direction(gps_point, bearing):\n",
    "    nearest_edge = None\n",
    "    min_distance = float('inf')\n",
    "    corrected_bearing = None\n",
    "    \n",
    "    # Mengubah titik GPS menjadi objek Point\n",
    "    point = Point(gps_point[1], gps_point[0])  # (longitude, latitude)\n",
    "    \n",
    "    # Iterasi melalui setiap edge dalam graph\n",
    "    for edge in G_corrected.edges(data=True):\n",
    "        start_node, end_node = edge[0], edge[1]\n",
    "        edge_line = LineString([start_node, end_node])\n",
    "        \n",
    "        # Menghitung jarak dari titik GPS ke edge\n",
    "        distance = point.distance(edge_line)\n",
    "        \n",
    "        # Jika jarak lebih kecil dari jarak minimum sebelumnya, simpan edge ini\n",
    "        if distance < min_distance:\n",
    "            # Menghitung bearing dari edge\n",
    "            edge_bearing = calculate_bearing(start_node[1], start_node[0], end_node[1], end_node[0])\n",
    "            bearing_diff = abs(edge_bearing - bearing) % 360\n",
    "            # Memastikan bearing dalam rentang yang masuk akal untuk kesesuaian arah\n",
    "            if bearing_diff < 90 or bearing_diff > 270:  # Asumsi toleransi arah +-90 derajat\n",
    "                min_distance = distance\n",
    "                nearest_edge = edge\n",
    "                corrected_bearing = edge_bearing\n",
    "                \n",
    "    return nearest_edge, min_distance, corrected_bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menyesuaikan koordinat GPS ke edge terdekat\n",
    "def adjust_gps_to_nearest_edge(row):\n",
    "    gps_point = (row['latitude'], row['longitude'])\n",
    "    bearing = row['bearing']\n",
    "    nearest_edge, distance, edge_bearing = find_nearest_edge_with_direction(gps_point, bearing)\n",
    "    \n",
    "    # Menggunakan titik terdekat pada edge sebagai koordinat yang disesuaikan\n",
    "    if nearest_edge:\n",
    "        edge_line = LineString([nearest_edge[0], nearest_edge[1]])\n",
    "        adjusted_point = edge_line.interpolate(edge_line.project(Point(gps_point[1], gps_point[0])))\n",
    "        adjusted_latitude, adjusted_longitude = adjusted_point.y, adjusted_point.x\n",
    "    else:\n",
    "        # Jika tidak ada edge terdekat yang sesuai, gunakan koordinat asli\n",
    "        adjusted_latitude, adjusted_longitude = row['latitude'], row['longitude']\n",
    "    \n",
    "    return pd.Series([row['maid'], row['latitude'], row['longitude'], row['timestamp'], adjusted_latitude, adjusted_longitude],\n",
    "                     index=['maid', 'latitude', 'longitude', 'timestamp', 'adjusted_latitude', 'adjusted_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bearings(gps_data): # Menambahkan kolom 'bearing' ke dataframe\n",
    "    bearings = []\n",
    "    for i in range(len(gps_data) - 1):\n",
    "        row1, row2 = gps_data.iloc[i], gps_data.iloc[i + 1]\n",
    "        bearing = calculate_bearing(row1['latitude'], row1['longitude'], row2['latitude'], row2['longitude'])\n",
    "        bearings.append(bearing)\n",
    "\n",
    "    # Untuk titik terakhir, kita ulangi bearing sebelumnya karena tidak ada titik setelahnya\n",
    "    bearings.append(bearings[-1])\n",
    "\n",
    "    gps_data['bearing'] = bearings\n",
    "    \n",
    "    return gps_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gps_to_nearest_edge_grouped(name, group):\n",
    "    adjusted_group = group.apply(adjust_gps_to_nearest_edge, axis=1)\n",
    "    return adjusted_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do pararell for multiple maid\n",
    "def adjust_path_parallel(data):\n",
    "    data['date'] = pd.to_datetime(data['timestamp']).dt.date\n",
    "    grouped = data.groupby(['maid', 'date'])\n",
    "    results = Parallel(n_jobs=40)(delayed(adjust_gps_to_nearest_edge_grouped)(name, group) for name, group in tqdm(grouped))\n",
    "    adjusted_gps_data = pd.concat(results, ignore_index=True)\n",
    "    \n",
    "    return adjusted_gps_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the GPS data\n",
    "gps_data = pd.read_csv('filter5_5m_malas_des.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do the process\n",
    "gps_data = add_bearings(gps_data) # Add bearings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_gps_data = adjust_path_parallel(gps_data)\n",
    "\n",
    "# Save the result\n",
    "adjusted_gps_data.to_csv('filter6_5m_malas_des.csv', index=False)\n",
    "adjusted_gps_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = adjusted_gps_data\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "a = data[(data['maid'] == 'd9f515f4-1a78-442b-81c4-55bf5f253b91') & (data['timestamp'].dt.date == pd.to_datetime('2021-12-06').date())]\n",
    "create_plot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Split trajectories based on observation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plot_defaults = {'linewidth':5, 'capstyle':'round', 'figsize':(9,3), 'legend':True}\n",
    "opts.defaults(opts.Overlay(active_tools=['wheel_zoom'], frame_width=500, frame_height=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_threshold(tdf, minute_gap):\n",
    "    index = 0\n",
    "    df_min = pd.DataFrame()\n",
    "\n",
    "    while index < len(tdf):\n",
    "        my_traj = tdf.trajectories[index]\n",
    "        split = mpd.ObservationGapSplitter(my_traj).split(gap=timedelta(minutes=minute_gap))\n",
    "        if len(split) > 1:\n",
    "            split_df = split.to_traj_gdf()\n",
    "            df_min = df_min._append(split_df, ignore_index=True)\n",
    "        index += 1\n",
    "\n",
    "    return df_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split_traj(threshold_df, original_df):\n",
    "    original_df['timestamp'] = pd.to_datetime(original_df['timestamp'])\n",
    "    split_gps_data = original_df.copy()\n",
    "    split_df = pd.DataFrame()\n",
    "    \n",
    "    for index, row in threshold_df.iterrows():\n",
    "        start_t = row['start_t']\n",
    "        end_t = row['end_t']\n",
    "        correlated_string = row['maid'].split('_')[-1]  # Get last two strings after \"_\"\n",
    "        mask = (original_df['timestamp'] >= start_t) & (original_df['timestamp'] <= end_t)\n",
    "        split_gps_data.loc[mask, 'maid'] = split_gps_data.loc[mask, 'maid'] + '_' + correlated_string\n",
    "        split_df = split_df._append(split_gps_data[mask])\n",
    "        \n",
    "    return split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_split_function(name, group, minute_gap):\n",
    "    tdf = mpd.TrajectoryCollection(group, traj_id_col='maid', t='timestamp', y='latitude', x='longitude')    \n",
    "    split_df = create_split_traj(create_threshold(tdf, minute_gap), group)\n",
    "    return split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do pararell for multiple maid\n",
    "def split_trajectory_parallel(data, minute_gap):\n",
    "    grouped = data.groupby('maid')\n",
    "    results = Parallel(n_jobs=20)(delayed(merge_split_function)(name, group, minute_gap) for name, group in tqdm(grouped))  \n",
    "    split_gps_data = pd.concat(results, ignore_index=True)\n",
    "    return split_gps_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                 | 0/21177 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                      | 80/21177 [00:00<01:31, 230.91it/s]\u001b[A\n",
      "  1%|                                     | 120/21177 [00:00<01:24, 248.33it/s]\u001b[A\n",
      "  1%|                                     | 160/21177 [00:00<01:18, 268.34it/s]\u001b[A\n",
      "  1%|                                     | 200/21177 [00:00<01:13, 284.77it/s]\u001b[A\n",
      "  1%|                                     | 240/21177 [00:00<01:11, 294.56it/s]\u001b[A\n",
      "  1%|                                     | 280/21177 [00:01<01:12, 287.57it/s]\u001b[A\n",
      "  2%|                                     | 320/21177 [00:01<01:09, 300.79it/s]\u001b[A\n",
      "  2%|                                     | 360/21177 [00:01<01:07, 308.71it/s]\u001b[A\n",
      "  2%|                                     | 400/21177 [00:01<01:06, 314.34it/s]\u001b[A\n",
      "  2%|                                     | 440/21177 [00:01<01:08, 303.13it/s]\u001b[A\n",
      "  2%|                                     | 480/21177 [00:01<01:08, 302.77it/s]\u001b[A\n",
      "  2%|                                     | 520/21177 [00:01<01:08, 302.57it/s]\u001b[A\n",
      "  3%|                                     | 560/21177 [00:01<01:07, 306.15it/s]\u001b[A\n",
      "  3%|                                     | 600/21177 [00:02<01:05, 315.67it/s]\u001b[A\n",
      "  3%|                                    | 640/21177 [00:02<01:04, 320.36it/s]\u001b[A\n",
      "  3%|                                    | 680/21177 [00:02<01:03, 322.14it/s]\u001b[A\n",
      "  3%|                                    | 720/21177 [00:02<01:02, 325.93it/s]\u001b[A\n",
      "  4%|                                    | 760/21177 [00:02<01:01, 334.60it/s]\u001b[A\n",
      "  4%|                                    | 800/21177 [00:02<01:04, 317.82it/s]\u001b[A\n",
      "  4%|                                    | 840/21177 [00:02<01:08, 299.05it/s]\u001b[A\n",
      "  4%|                                    | 880/21177 [00:02<01:08, 296.60it/s]\u001b[A\n",
      "  4%|                                    | 920/21177 [00:03<01:09, 291.68it/s]\u001b[A\n",
      "  5%|                                    | 960/21177 [00:03<01:09, 292.26it/s]\u001b[A\n",
      "  5%|                                   | 1000/21177 [00:03<01:08, 294.62it/s]\u001b[A\n",
      "  5%|                                   | 1040/21177 [00:03<01:05, 308.20it/s]\u001b[A\n",
      "  5%|                                   | 1080/21177 [00:03<01:05, 308.99it/s]\u001b[A\n",
      "  5%|                                   | 1120/21177 [00:03<01:06, 302.35it/s]\u001b[A\n",
      "  5%|                                   | 1160/21177 [00:03<01:09, 290.02it/s]\u001b[A\n",
      "  6%|                                   | 1200/21177 [00:04<01:06, 301.33it/s]\u001b[A\n",
      "  6%|                                  | 1240/21177 [00:04<01:04, 309.76it/s]\u001b[A\n",
      "  6%|                                  | 1280/21177 [00:04<01:02, 316.64it/s]\u001b[A\n",
      "  6%|                                  | 1320/21177 [00:04<01:01, 324.26it/s]\u001b[A\n",
      "  6%|                                  | 1360/21177 [00:04<01:00, 328.04it/s]\u001b[A\n",
      "  7%|                                  | 1400/21177 [00:04<00:59, 329.75it/s]\u001b[A\n",
      "  7%|                                  | 1440/21177 [00:04<00:58, 338.59it/s]\u001b[A\n",
      "  7%|                                  | 1480/21177 [00:04<00:57, 341.00it/s]\u001b[A\n",
      "  7%|                                  | 1520/21177 [00:04<01:00, 327.05it/s]\u001b[A\n",
      "  7%|                                  | 1560/21177 [00:05<01:02, 312.65it/s]\u001b[A\n",
      "  8%|                                  | 1640/21177 [00:05<00:57, 341.45it/s]\u001b[A\n",
      "  8%|                                  | 1720/21177 [00:05<00:50, 384.29it/s]\u001b[A\n",
      "  8%|                                 | 1800/21177 [00:05<00:44, 437.98it/s]\u001b[A\n",
      "  9%|                                 | 1880/21177 [00:05<00:40, 479.54it/s]\u001b[A\n",
      "  9%|                                 | 1960/21177 [00:05<00:37, 507.04it/s]\u001b[A\n",
      " 10%|                                 | 2040/21177 [00:06<00:36, 528.83it/s]\u001b[A\n",
      " 10%|                                 | 2120/21177 [00:06<00:35, 538.35it/s]\u001b[A\n",
      " 10%|                                 | 2200/21177 [00:06<00:35, 533.29it/s]\u001b[A\n",
      " 11%|                                 | 2280/21177 [00:06<00:35, 532.46it/s]\u001b[A\n",
      " 11%|                                 | 2360/21177 [00:06<00:35, 525.16it/s]\u001b[A\n",
      " 12%|                                | 2440/21177 [00:06<00:36, 508.96it/s]\u001b[A\n",
      " 12%|                                | 2520/21177 [00:06<00:37, 504.00it/s]\u001b[A\n",
      " 12%|                                | 2600/21177 [00:07<00:36, 504.11it/s]\u001b[A\n",
      " 13%|                                | 2680/21177 [00:07<00:38, 479.00it/s]\u001b[A\n",
      " 13%|                                | 2760/21177 [00:07<00:41, 447.91it/s]\u001b[A\n",
      " 13%|                                | 2840/21177 [00:07<00:38, 479.32it/s]\u001b[A\n",
      " 14%|                                | 2920/21177 [00:07<00:36, 495.36it/s]\u001b[A\n",
      " 14%|                               | 3000/21177 [00:07<00:35, 518.44it/s]\u001b[A\n",
      " 15%|                               | 3080/21177 [00:08<00:33, 545.46it/s]\u001b[A\n",
      " 15%|                               | 3160/21177 [00:08<00:32, 558.80it/s]\u001b[A\n",
      " 15%|                               | 3240/21177 [00:08<00:32, 558.83it/s]\u001b[A\n",
      " 16%|                               | 3320/21177 [00:08<00:31, 559.07it/s]\u001b[A\n",
      " 16%|                               | 3400/21177 [00:08<00:31, 565.55it/s]\u001b[A\n",
      " 16%|                               | 3480/21177 [00:08<00:31, 568.72it/s]\u001b[A\n",
      " 17%|                              | 3560/21177 [00:08<00:30, 569.25it/s]\u001b[A\n",
      " 17%|                              | 3640/21177 [00:09<00:31, 556.89it/s]\u001b[A\n",
      " 18%|                              | 3720/21177 [00:09<00:33, 519.88it/s]\u001b[A\n",
      " 18%|                              | 3800/21177 [00:09<00:35, 494.42it/s]\u001b[A\n",
      " 18%|                              | 3880/21177 [00:09<00:34, 496.82it/s]\u001b[A\n",
      " 19%|                              | 3960/21177 [00:09<00:34, 493.47it/s]\u001b[A\n",
      " 19%|                              | 4040/21177 [00:09<00:34, 497.01it/s]\u001b[A\n",
      " 19%|                             | 4120/21177 [00:10<00:33, 510.00it/s]\u001b[A\n",
      " 20%|                             | 4200/21177 [00:10<00:31, 533.84it/s]\u001b[A\n",
      " 20%|                             | 4280/21177 [00:10<00:31, 530.83it/s]\u001b[A\n",
      " 21%|                             | 4360/21177 [00:10<00:31, 529.27it/s]\u001b[A\n",
      " 21%|                             | 4440/21177 [00:10<00:31, 525.01it/s]\u001b[A\n",
      " 21%|                             | 4520/21177 [00:10<00:32, 519.73it/s]\u001b[A\n",
      " 22%|                             | 4600/21177 [00:10<00:32, 515.81it/s]\u001b[A\n",
      " 22%|                            | 4680/21177 [00:11<00:31, 525.50it/s]\u001b[A\n",
      " 22%|                            | 4760/21177 [00:11<00:32, 498.69it/s]\u001b[A\n",
      " 23%|                            | 4840/21177 [00:11<00:32, 509.36it/s]\u001b[A\n",
      " 23%|                            | 4920/21177 [00:11<00:30, 526.03it/s]\u001b[A\n",
      " 24%|                            | 5000/21177 [00:11<00:30, 529.75it/s]\u001b[A\n",
      " 24%|                            | 5080/21177 [00:11<00:29, 541.84it/s]\u001b[A\n",
      " 24%|                            | 5160/21177 [00:11<00:28, 556.37it/s]\u001b[A\n",
      " 25%|                           | 5240/21177 [00:12<00:28, 562.29it/s]\u001b[A\n",
      " 25%|                           | 5320/21177 [00:12<00:28, 564.20it/s]\u001b[A\n",
      " 25%|                           | 5400/21177 [00:12<00:28, 545.67it/s]\u001b[A\n",
      " 26%|                           | 5480/21177 [00:12<00:29, 537.49it/s]\u001b[A\n",
      " 26%|                           | 5560/21177 [00:12<00:29, 532.17it/s]\u001b[A\n",
      " 27%|                           | 5640/21177 [00:12<00:28, 544.23it/s]\u001b[A\n",
      " 27%|                           | 5720/21177 [00:13<00:27, 554.69it/s]\u001b[A\n",
      " 27%|                          | 5800/21177 [00:13<00:27, 562.03it/s]\u001b[A\n",
      " 28%|                          | 5880/21177 [00:13<00:26, 569.10it/s]\u001b[A\n",
      " 28%|                          | 5960/21177 [00:13<00:26, 574.55it/s]\u001b[A\n",
      " 29%|                          | 6040/21177 [00:13<00:26, 561.64it/s]\u001b[A\n",
      " 29%|                          | 6120/21177 [00:13<00:27, 553.11it/s]\u001b[A\n",
      " 29%|                          | 6200/21177 [00:13<00:27, 537.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|                          | 6280/21177 [00:14<00:27, 534.13it/s]\u001b[A\n",
      " 30%|                          | 6360/21177 [00:14<00:27, 546.63it/s]\u001b[A\n",
      " 30%|                         | 6440/21177 [00:14<00:26, 559.55it/s]\u001b[A\n",
      " 31%|                         | 6520/21177 [00:14<00:26, 562.29it/s]\u001b[A\n",
      " 31%|                         | 6600/21177 [00:14<00:25, 571.35it/s]\u001b[A\n",
      " 32%|                         | 6680/21177 [00:14<00:25, 574.44it/s]\u001b[A\n",
      " 32%|                         | 6760/21177 [00:14<00:25, 565.49it/s]\u001b[A\n",
      " 32%|                         | 6840/21177 [00:15<00:26, 545.47it/s]\u001b[A\n",
      " 33%|                         | 6920/21177 [00:15<00:26, 531.65it/s]\u001b[A\n",
      " 33%|                        | 6974/21177 [00:15<00:36, 389.35it/s]\u001b[A\n",
      " 33%|                        | 7018/21177 [00:15<00:39, 357.89it/s]\u001b[A\n",
      " 33%|                        | 7080/21177 [00:15<00:39, 353.51it/s]\u001b[A\n",
      " 34%|                        | 7160/21177 [00:15<00:35, 396.31it/s]\u001b[A\n",
      " 34%|                        | 7240/21177 [00:16<00:32, 429.70it/s]\u001b[A\n",
      " 35%|                        | 7320/21177 [00:16<00:29, 465.81it/s]\u001b[A\n",
      " 35%|                        | 7400/21177 [00:16<00:28, 480.15it/s]\u001b[A\n",
      " 35%|                        | 7480/21177 [00:16<00:28, 481.83it/s]\u001b[A\n",
      " 36%|                       | 7560/21177 [00:16<00:26, 510.17it/s]\u001b[A\n",
      " 36%|                       | 7640/21177 [00:16<00:25, 534.19it/s]\u001b[A\n",
      " 36%|                       | 7720/21177 [00:16<00:24, 544.80it/s]\u001b[A\n",
      " 37%|                       | 7800/21177 [00:17<00:24, 551.95it/s]\u001b[A\n",
      " 37%|                       | 7880/21177 [00:17<00:24, 538.85it/s]\u001b[A\n",
      " 38%|                       | 7960/21177 [00:17<00:24, 528.88it/s]\u001b[A\n",
      " 38%|                       | 8040/21177 [00:17<00:24, 528.81it/s]\u001b[A\n",
      " 38%|                      | 8120/21177 [00:17<00:27, 475.57it/s]\u001b[A\n",
      " 39%|                      | 8200/21177 [00:17<00:26, 487.27it/s]\u001b[A\n",
      " 39%|                      | 8280/21177 [00:18<00:26, 488.58it/s]\u001b[A\n",
      " 39%|                      | 8360/21177 [00:18<00:26, 479.54it/s]\u001b[A\n",
      " 40%|                      | 8440/21177 [00:18<00:26, 481.39it/s]\u001b[A\n",
      " 40%|                      | 8520/21177 [00:18<00:25, 487.11it/s]\u001b[A\n",
      " 41%|                      | 8600/21177 [00:18<00:24, 523.62it/s]\u001b[A\n",
      " 41%|                     | 8680/21177 [00:18<00:23, 531.73it/s]\u001b[A\n",
      " 41%|                     | 8760/21177 [00:19<00:23, 525.35it/s]\u001b[A\n",
      " 42%|                     | 8840/21177 [00:19<00:23, 524.00it/s]\u001b[A\n",
      " 42%|                     | 8920/21177 [00:19<00:23, 519.96it/s]\u001b[A\n",
      " 42%|                     | 9000/21177 [00:19<00:23, 517.75it/s]\u001b[A\n",
      " 43%|                     | 9080/21177 [00:19<00:22, 537.52it/s]\u001b[A\n",
      " 43%|                     | 9160/21177 [00:19<00:22, 543.13it/s]\u001b[A\n",
      " 44%|                    | 9240/21177 [00:19<00:22, 534.11it/s]\u001b[A\n",
      " 44%|                    | 9320/21177 [00:20<00:21, 547.28it/s]\u001b[A\n",
      " 44%|                    | 9400/21177 [00:20<00:21, 554.74it/s]\u001b[A\n",
      " 45%|                    | 9480/21177 [00:20<00:23, 507.62it/s]\u001b[A\n",
      " 45%|                    | 9560/21177 [00:20<00:22, 512.37it/s]\u001b[A\n",
      " 46%|                    | 9640/21177 [00:20<00:23, 498.72it/s]\u001b[A\n",
      " 46%|                    | 9720/21177 [00:20<00:22, 504.19it/s]\u001b[A\n",
      " 46%|                    | 9800/21177 [00:21<00:22, 502.77it/s]\u001b[A\n",
      " 47%|                   | 9880/21177 [00:21<00:22, 500.19it/s]\u001b[A\n",
      " 47%|                   | 9960/21177 [00:21<00:22, 489.56it/s]\u001b[A\n",
      " 47%|                   | 10040/21177 [00:21<00:22, 497.89it/s]\u001b[A\n",
      " 48%|                  | 10120/21177 [00:21<00:21, 503.75it/s]\u001b[A\n",
      " 48%|                  | 10200/21177 [00:21<00:21, 507.83it/s]\u001b[A\n",
      " 49%|                  | 10280/21177 [00:22<00:21, 502.86it/s]\u001b[A\n",
      " 49%|                  | 10360/21177 [00:22<00:20, 523.09it/s]\u001b[A\n",
      " 49%|                  | 10440/21177 [00:22<00:19, 542.29it/s]\u001b[A\n",
      " 50%|                  | 10520/21177 [00:22<00:19, 541.90it/s]\u001b[A\n",
      " 50%|                  | 10600/21177 [00:22<00:19, 553.17it/s]\u001b[A\n",
      " 50%|                 | 10680/21177 [00:22<00:18, 557.05it/s]\u001b[A\n",
      " 51%|                 | 10760/21177 [00:22<00:19, 545.75it/s]\u001b[A\n",
      " 51%|                 | 10840/21177 [00:22<00:18, 558.71it/s]\u001b[A\n",
      " 52%|                 | 10920/21177 [00:23<00:18, 565.26it/s]\u001b[A\n",
      " 52%|                 | 11000/21177 [00:23<00:17, 574.74it/s]\u001b[A\n",
      " 52%|                 | 11080/21177 [00:23<00:17, 567.65it/s]\u001b[A\n",
      " 53%|                 | 11160/21177 [00:23<00:17, 556.54it/s]\u001b[A\n",
      " 53%|                 | 11240/21177 [00:23<00:17, 567.32it/s]\u001b[A\n",
      " 53%|                | 11320/21177 [00:23<00:17, 574.46it/s]\u001b[A\n",
      " 54%|                | 11400/21177 [00:23<00:16, 576.81it/s]\u001b[A\n",
      " 54%|                | 11480/21177 [00:24<00:16, 578.70it/s]\u001b[A\n",
      " 55%|                | 11560/21177 [00:24<00:17, 561.51it/s]\u001b[A\n",
      " 55%|                | 11640/21177 [00:24<00:18, 529.55it/s]\u001b[A\n",
      " 55%|                | 11720/21177 [00:24<00:17, 525.41it/s]\u001b[A\n",
      " 56%|                | 11800/21177 [00:24<00:17, 526.93it/s]\u001b[A\n",
      " 56%|               | 11880/21177 [00:24<00:17, 529.02it/s]\u001b[A\n",
      " 56%|               | 11960/21177 [00:25<00:17, 534.48it/s]\u001b[A\n",
      " 57%|               | 12040/21177 [00:25<00:16, 553.50it/s]\u001b[A\n",
      " 57%|               | 12120/21177 [00:25<00:15, 570.31it/s]\u001b[A\n",
      " 58%|               | 12200/21177 [00:25<00:15, 581.19it/s]\u001b[A\n",
      " 58%|               | 12280/21177 [00:25<00:15, 580.20it/s]\u001b[A\n",
      " 58%|               | 12360/21177 [00:25<00:15, 587.03it/s]\u001b[A\n",
      " 59%|              | 12440/21177 [00:25<00:15, 568.28it/s]\u001b[A\n",
      " 59%|              | 12520/21177 [00:25<00:15, 572.10it/s]\u001b[A\n",
      " 59%|              | 12600/21177 [00:26<00:14, 582.04it/s]\u001b[A\n",
      " 60%|              | 12680/21177 [00:26<00:15, 556.53it/s]\u001b[A\n",
      " 60%|              | 12760/21177 [00:26<00:16, 511.04it/s]\u001b[A\n",
      " 61%|              | 12840/21177 [00:26<00:16, 494.78it/s]\u001b[A\n",
      " 61%|              | 12920/21177 [00:26<00:15, 516.37it/s]\u001b[A\n",
      " 61%|              | 13000/21177 [00:26<00:16, 484.25it/s]\u001b[A\n",
      " 62%|             | 13080/21177 [00:27<00:15, 507.64it/s]\u001b[A\n",
      " 62%|             | 13160/21177 [00:27<00:15, 524.19it/s]\u001b[A\n",
      " 63%|             | 13240/21177 [00:27<00:14, 542.36it/s]\u001b[A\n",
      " 63%|             | 13320/21177 [00:27<00:15, 514.98it/s]\u001b[A\n",
      " 63%|             | 13400/21177 [00:27<00:15, 513.94it/s]\u001b[A\n",
      " 64%|             | 13480/21177 [00:27<00:14, 516.68it/s]\u001b[A\n",
      " 64%|             | 13560/21177 [00:28<00:14, 513.99it/s]\u001b[A\n",
      " 64%|            | 13640/21177 [00:28<00:14, 517.25it/s]\u001b[A\n",
      " 65%|            | 13720/21177 [00:28<00:14, 532.19it/s]\u001b[A\n",
      " 65%|            | 13800/21177 [00:28<00:13, 543.83it/s]\u001b[A\n",
      " 66%|            | 13880/21177 [00:28<00:14, 520.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|            | 13960/21177 [00:28<00:14, 497.96it/s]\u001b[A\n",
      " 66%|            | 14040/21177 [00:28<00:14, 485.59it/s]\u001b[A\n",
      " 67%|            | 14120/21177 [00:29<00:14, 495.45it/s]\u001b[A\n",
      " 67%|           | 14200/21177 [00:29<00:13, 519.06it/s]\u001b[A\n",
      " 67%|           | 14280/21177 [00:29<00:13, 525.17it/s]\u001b[A\n",
      " 68%|           | 14360/21177 [00:29<00:12, 540.12it/s]\u001b[A\n",
      " 68%|           | 14440/21177 [00:29<00:12, 551.51it/s]\u001b[A\n",
      " 69%|           | 14520/21177 [00:29<00:12, 545.43it/s]\u001b[A\n",
      " 69%|           | 14600/21177 [00:29<00:11, 557.80it/s]\u001b[A\n",
      " 69%|           | 14680/21177 [00:30<00:11, 560.10it/s]\u001b[A\n",
      " 70%|           | 14760/21177 [00:30<00:12, 526.99it/s]\u001b[A\n",
      " 70%|          | 14840/21177 [00:30<00:12, 505.62it/s]\u001b[A\n",
      " 70%|          | 14920/21177 [00:30<00:11, 543.48it/s]\u001b[A\n",
      " 71%|          | 15000/21177 [00:30<00:10, 572.72it/s]\u001b[A\n",
      " 71%|          | 15080/21177 [00:30<00:11, 550.01it/s]\u001b[A\n",
      " 72%|          | 15160/21177 [00:31<00:11, 520.59it/s]\u001b[A\n",
      " 72%|          | 15240/21177 [00:31<00:11, 513.55it/s]\u001b[A\n",
      " 72%|          | 15320/21177 [00:31<00:11, 507.94it/s]\u001b[A\n",
      " 73%|         | 15400/21177 [00:31<00:11, 509.96it/s]\u001b[A\n",
      " 73%|         | 15480/21177 [00:31<00:11, 513.25it/s]\u001b[A\n",
      " 73%|         | 15560/21177 [00:31<00:11, 509.33it/s]\u001b[A\n",
      " 74%|         | 15625/21177 [00:32<00:15, 367.71it/s]\u001b[A\n",
      " 74%|         | 15667/21177 [00:32<00:16, 333.23it/s]\u001b[A\n",
      " 74%|         | 15720/21177 [00:32<00:16, 334.54it/s]\u001b[A\n",
      " 75%|         | 15800/21177 [00:32<00:14, 383.31it/s]\u001b[A\n",
      " 75%|         | 15880/21177 [00:32<00:12, 418.00it/s]\u001b[A\n",
      " 75%|        | 15960/21177 [00:32<00:11, 457.80it/s]\u001b[A\n",
      " 76%|        | 16040/21177 [00:33<00:10, 479.51it/s]\u001b[A\n",
      " 76%|        | 16120/21177 [00:33<00:09, 515.37it/s]\u001b[A\n",
      " 76%|        | 16200/21177 [00:33<00:10, 495.47it/s]\u001b[A\n",
      " 77%|        | 16280/21177 [00:33<00:09, 499.65it/s]\u001b[A\n",
      " 77%|        | 16360/21177 [00:33<00:09, 512.53it/s]\u001b[A\n",
      " 78%|        | 16440/21177 [00:33<00:09, 509.50it/s]\u001b[A\n",
      " 78%|        | 16520/21177 [00:34<00:09, 506.49it/s]\u001b[A\n",
      " 78%|       | 16600/21177 [00:34<00:08, 520.56it/s]\u001b[A\n",
      " 79%|       | 16680/21177 [00:34<00:08, 532.45it/s]\u001b[A\n",
      " 79%|       | 16760/21177 [00:34<00:08, 518.49it/s]\u001b[A\n",
      " 80%|       | 16840/21177 [00:34<00:08, 513.01it/s]\u001b[A\n",
      " 80%|       | 16920/21177 [00:34<00:08, 514.89it/s]\u001b[A\n",
      " 80%|       | 17000/21177 [00:34<00:08, 515.45it/s]\u001b[A\n",
      " 81%|       | 17080/21177 [00:35<00:07, 518.79it/s]\u001b[A\n",
      " 81%|      | 17160/21177 [00:35<00:07, 527.04it/s]\u001b[A\n",
      " 81%|      | 17240/21177 [00:35<00:07, 543.13it/s]\u001b[A\n",
      " 82%|      | 17320/21177 [00:35<00:06, 559.38it/s]\u001b[A\n",
      " 82%|      | 17400/21177 [00:35<00:06, 564.74it/s]\u001b[A\n",
      " 83%|      | 17480/21177 [00:35<00:06, 540.98it/s]\u001b[A\n",
      " 83%|      | 17560/21177 [00:35<00:06, 527.80it/s]\u001b[A\n",
      " 83%|      | 17640/21177 [00:36<00:07, 504.33it/s]\u001b[A\n",
      " 84%|      | 17720/21177 [00:36<00:07, 477.42it/s]\u001b[A\n",
      " 84%|     | 17800/21177 [00:36<00:06, 490.07it/s]\u001b[A\n",
      " 84%|     | 17880/21177 [00:36<00:06, 491.53it/s]\u001b[A\n",
      " 85%|     | 17960/21177 [00:36<00:06, 483.61it/s]\u001b[A\n",
      " 85%|     | 18040/21177 [00:36<00:06, 487.91it/s]\u001b[A\n",
      " 86%|     | 18120/21177 [00:37<00:06, 487.11it/s]\u001b[A\n",
      " 86%|     | 18200/21177 [00:37<00:06, 495.81it/s]\u001b[A\n",
      " 86%|     | 18280/21177 [00:37<00:05, 518.75it/s]\u001b[A\n",
      " 87%|    | 18360/21177 [00:37<00:05, 512.29it/s]\u001b[A\n",
      " 87%|    | 18440/21177 [00:37<00:05, 503.64it/s]\u001b[A\n",
      " 87%|    | 18520/21177 [00:37<00:05, 489.44it/s]\u001b[A\n",
      " 88%|    | 18600/21177 [00:38<00:04, 530.23it/s]\u001b[A\n",
      " 88%|    | 18680/21177 [00:38<00:05, 466.50it/s]\u001b[A\n",
      " 89%|    | 18760/21177 [00:38<00:04, 501.18it/s]\u001b[A\n",
      " 89%|    | 18840/21177 [00:38<00:04, 522.86it/s]\u001b[A\n",
      " 89%|   | 18920/21177 [00:38<00:04, 539.53it/s]\u001b[A\n",
      " 90%|   | 19000/21177 [00:38<00:03, 547.14it/s]\u001b[A\n",
      " 90%|   | 19080/21177 [00:38<00:03, 528.91it/s]\u001b[A\n",
      " 90%|   | 19160/21177 [00:39<00:03, 522.85it/s]\u001b[A\n",
      " 91%|   | 19240/21177 [00:39<00:03, 545.69it/s]\u001b[A\n",
      " 91%|   | 19320/21177 [00:39<00:03, 530.76it/s]\u001b[A\n",
      " 92%|   | 19400/21177 [00:39<00:03, 537.46it/s]\u001b[A\n",
      " 92%|   | 19480/21177 [00:39<00:03, 544.10it/s]\u001b[A\n",
      " 92%|  | 19560/21177 [00:39<00:03, 530.55it/s]\u001b[A\n",
      " 93%|  | 19640/21177 [00:40<00:03, 495.99it/s]\u001b[A\n",
      " 93%|  | 19720/21177 [00:40<00:03, 481.95it/s]\u001b[A\n",
      " 93%|  | 19800/21177 [00:40<00:02, 511.62it/s]\u001b[A\n",
      " 94%|  | 19880/21177 [00:40<00:02, 533.70it/s]\u001b[A\n",
      " 94%|  | 19960/21177 [00:40<00:02, 555.58it/s]\u001b[A\n",
      " 95%|  | 20040/21177 [00:40<00:02, 554.48it/s]\u001b[A\n",
      " 95%| | 20120/21177 [00:40<00:01, 559.88it/s]\u001b[A\n",
      " 95%| | 20200/21177 [00:41<00:01, 553.04it/s]\u001b[A\n",
      " 96%| | 20280/21177 [00:41<00:01, 521.56it/s]\u001b[A\n",
      " 96%| | 20360/21177 [00:41<00:01, 516.81it/s]\u001b[A\n",
      " 97%| | 20440/21177 [00:41<00:01, 543.34it/s]\u001b[A\n",
      " 97%| | 20520/21177 [00:41<00:01, 554.08it/s]\u001b[A\n",
      " 97%| | 20600/21177 [00:41<00:01, 556.09it/s]\u001b[A\n",
      " 98%|| 20680/21177 [00:41<00:00, 560.90it/s]\u001b[A\n",
      " 98%|| 20760/21177 [00:42<00:00, 597.97it/s]\u001b[A\n",
      " 98%|| 20840/21177 [00:42<00:00, 554.40it/s]\u001b[A\n",
      " 99%|| 20920/21177 [00:42<00:00, 564.16it/s]\u001b[A\n",
      " 99%|| 21000/21177 [00:42<00:00, 570.42it/s]\u001b[A\n",
      "100%|| 21080/21177 [00:42<00:00, 560.12it/s]\u001b[A\n",
      "100%|| 21177/21177 [00:42<00:00, 494.73it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# Read the GPS data\n",
    "data_mpd = pd.read_csv('filter6_5m_malas_des.csv')\n",
    "\n",
    "# Do the process\n",
    "minute_gap = 5 #Change this variable to choose the observation timedelta gap\n",
    "split_gps_data = split_trajectory_parallel(data_mpd, minute_gap)\n",
    "\n",
    "# Save the result\n",
    "split_gps_data.to_csv(f\"filter7_5m_{minute_gap}m_malas_des.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Path reconstruction with PyTrack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pytrack.graph import graph, distance, download\n",
    "from pytrack.analytics import visualization\n",
    "from pytrack.matching import candidate, mpmatching_utils, mpmatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrack.graph import graph, distance, download\n",
    "from pytrack.analytics import visualization\n",
    "from pytrack.matching import candidate, mpmatching_utils, mpmatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the GPS data\n",
    "df = pd.read_csv('filter7_5m_5m_malas_des.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_matching_pytrack(name, group, graph):\n",
    "    df = group\n",
    "    G = graph\n",
    "    maid = df['maid'].values[0]\n",
    "\n",
    "    latitude = df[\"adjusted_latitude\"].to_list()\n",
    "    longitude = df[\"adjusted_longitude\"].to_list()\n",
    "    points = [(lat, lon) for lat, lon in zip(latitude, longitude)]\n",
    "\n",
    "    # Extract candidates\n",
    "    G_interp, candidates = candidate.get_candidates(G, points, interp_dist=10, closest=True, radius=30)\n",
    "\n",
    "    # Extract trellis DAG graph\n",
    "    trellis = mpmatching_utils.create_trellis(candidates)\n",
    "\n",
    "    # Perform the map-matching process\n",
    "    path_prob, predecessor = mpmatching.viterbi_search(G_interp, trellis, \"start\", \"target\")\n",
    "\n",
    "    path_df = pd.DataFrame()\n",
    "    bad_df = pd.DataFrame()\n",
    "\n",
    "    # Extract the path results from map-matching process\n",
    "    if len(predecessor) > 0:\n",
    "        node, path = mpmatching_utils.create_matched_path(G_interp, trellis, predecessor)\n",
    "\n",
    "        # Create constructed path\n",
    "        path_df = pd.DataFrame(path)\n",
    "        path_df = path_df.rename(columns={0:'latitude', 1:'longitude'})\n",
    "        path_df.insert(loc=0, column='maid', value=maid)\n",
    "\n",
    "    else:\n",
    "        bad_df = bad_df._append({'bad_maid': maid}, ignore_index=True)\n",
    "\n",
    "    return path_df, bad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = df[\"adjusted_latitude\"].to_list()\n",
    "longitude = df[\"adjusted_longitude\"].to_list()\n",
    "\n",
    "points = [(lat, lon) for lat, lon in zip(latitude, longitude)]\n",
    "north, east = np.max(np.array([*points]), 0)\n",
    "south, west = np.min(np.array([*points]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1,377.20kB\n"
     ]
    }
   ],
   "source": [
    "G = graph.graph_from_bbox(*distance.enlarge_bbox(north, south, west, east, 300), simplify=True, network_type='drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urutkan_maid(df, maid):\n",
    "    # Ekstrak angka terakhir dari setiap elemen dalam kolom 'bad_maid'\n",
    "    df['last_number'] = df[maid].str.extract(r'_(\\d+)$')\n",
    "\n",
    "    # Ubah angka terakhir menjadi tipe data numerik\n",
    "    df['last_number'] = pd.to_numeric(df['last_number'])\n",
    "\n",
    "    # Urutkan DataFrame berdasarkan angka terakhir secara numerik\n",
    "    df = df.sort_values(by='last_number', ignore_index=True)\n",
    "\n",
    "    # Hapus kolom 'last_number' jika tidak diperlukan lagi\n",
    "    df.drop(columns='last_number', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by trajectories to perform Map Matching with PyTrack\n",
    "def map_matching_pytrack_parallel(data, G):\n",
    "    grouped = data.groupby('maid')\n",
    "    results, bad_paths = zip(*(Parallel(n_jobs=40)(delayed(map_matching_pytrack)(name, group, G) for name, group in tqdm(grouped))))\n",
    "    matched_path = urutkan_maid(pd.concat(results, ignore_index=True), 'maid')\n",
    "    bad_path = urutkan_maid(pd.concat(bad_paths, ignore_index=True), 'bad_maid')\n",
    "    \n",
    "    return matched_path, bad_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/1532 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|                                        | 40/1532 [00:00<00:30, 49.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|                                      | 80/1532 [00:10<03:47,  6.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|                                    | 120/1532 [00:14<02:56,  8.00it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "GEOSException",
     "evalue": "IllegalArgumentException: point array must contain 0 or >1 elements\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/raid/arkham/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"/raid/arkham/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/raid/arkham/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/raid/arkham/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/parallel.py\", line 263, in __call__\n    return [func(*args, **kwargs)\n  File \"/raid/arkham/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/ipykernel_11642/2115196582.py\", line 24, in map_matching_pytrack\n  File \"/raid/arkham/miniconda3/envs/arkham/lib/python3.10/site-packages/pytrack/matching/mpmatching_utils.py\", line 172, in create_matched_path\n    path_coords = [(lat, lng) for lng, lat in LineString([G.nodes[node][\"geometry\"] for node in node_ids]).coords]\n  File \"/raid/arkham/miniconda3/envs/arkham/lib/python3.10/site-packages/shapely/geometry/linestring.py\", line 73, in __new__\n    geom = shapely.linestrings(coordinates)\n  File \"/raid/arkham/miniconda3/envs/arkham/lib/python3.10/site-packages/shapely/decorators.py\", line 77, in wrapped\n    return func(*args, **kwargs)\n  File \"/raid/arkham/miniconda3/envs/arkham/lib/python3.10/site-packages/shapely/creation.py\", line 120, in linestrings\n    return lib.linestrings(coords, out=out, **kwargs)\nshapely.errors.GEOSException: IllegalArgumentException: point array must contain 0 or >1 elements\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGEOSException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Do the process\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Perform the map matching process for all maid\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m matched_path, bad_path \u001b[38;5;241m=\u001b[39m \u001b[43mmap_matching_pytrack_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m, in \u001b[0;36mmap_matching_pytrack_parallel\u001b[0;34m(data, G)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_matching_pytrack_parallel\u001b[39m(data, G):\n\u001b[1;32m      3\u001b[0m     grouped \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     results, bad_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_matching_pytrack\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrouped\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      5\u001b[0m     matched_path \u001b[38;5;241m=\u001b[39m urutkan_maid(pd\u001b[38;5;241m.\u001b[39mconcat(results, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     bad_path \u001b[38;5;241m=\u001b[39m urutkan_maid(pd\u001b[38;5;241m.\u001b[39mconcat(bad_paths, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad_maid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/envs/arkham/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkham/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/envs/arkham/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mGEOSException\u001b[0m: IllegalArgumentException: point array must contain 0 or >1 elements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  8%|                                    | 120/1532 [00:28<02:56,  8.00it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# Do the process\n",
    "# Perform the map matching process for all maid\n",
    "matched_path, bad_path = map_matching_pytrack_parallel(df, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Time interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "def find_nearest_point_index(lat, lon, points_df):\n",
    "    distances = distance_matrix(points_df[['latitude', 'longitude']], [(lat, lon)])\n",
    "    nearest_point_index = np.argmin(distances)\n",
    "    return nearest_point_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timestamp_to_nearest_point(path_df, df):\n",
    "    nearest_points_timestamp = {}  # Dictionary to store timestamps for each nearest point index\n",
    "    for index, row in df.iterrows():\n",
    "        nearest_point_index = find_nearest_point_index(row['adjusted_latitude'], row['adjusted_longitude'], path_df)\n",
    "        if nearest_point_index not in nearest_points_timestamp:\n",
    "            nearest_points_timestamp[nearest_point_index] = row['timestamp']\n",
    "        else:\n",
    "            # If multiple points share the same nearest point index, choose the latest timestamp\n",
    "            nearest_points_timestamp[nearest_point_index] = max(nearest_points_timestamp[nearest_point_index], row['timestamp'])\n",
    "    \n",
    "    # Assign timestamps to the nearest points in path_df\n",
    "    path_df['timestamp'] = path_df.index.map(lambda idx: nearest_points_timestamp.get(idx))\n",
    "    \n",
    "    return path_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv(\"df.csv\")\n",
    "path_df_30persen = pd.read_csv(\"path_df_30persen.csv\")\n",
    "path_df_60persen = path_df_30persen[::2]\n",
    "hasil = add_timestamp_to_nearest_point(path_df_60persen, df)\n",
    "hasil.reset_index(inplace=False, drop=True)\n",
    "hasil[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
